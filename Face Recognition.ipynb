{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GPU growth\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up folder Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_PATH = os.path.join(\"data\", \"positive\")\n",
    "NEG_PATH = os.path.join(\"data\", \"negative\")\n",
    "ANC_PATH = os.path.join(\"data\", \"anchor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Directories\n",
    "os.makedirs(POS_PATH)\n",
    "os.makedirs(NEG_PATH)\n",
    "os.makedirs(ANC_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncompress tar file and move images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf lfw.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in os.listdir(\"lfw\"):\n",
    "    for file in os.listdir(os.path.join('lfw', directory)):\n",
    "        EX_PATH = os.path.join(\"lfw\", directory, file)\n",
    "        NEW_PATH = os.path.join(NEG_PATH, file)\n",
    "        os.replace(EX_PATH, NEW_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Positive and Anchor class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images are collected using image collector file which uses openCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_aug(img):\n",
    "    data = []\n",
    "    for i in range(9):\n",
    "        img = tf.image.stateless_random_brightness(img, max_delta=0.02, seed=(1,2))\n",
    "        img = tf.image.stateless_random_contrast(img, lower=0.6, upper=1, seed=(1,3))\n",
    "        # img = tf.image.stateless_random_crop(img, size=(20,20,3), seed=(1,2))\n",
    "        img = tf.image.stateless_random_flip_left_right(img, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        img = tf.image.stateless_random_jpeg_quality(img, min_jpeg_quality=90, max_jpeg_quality=100, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        img = tf.image.stateless_random_saturation(img, lower=0.9,upper=1, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "            \n",
    "        data.append(img)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(os.path.join(POS_PATH)):\n",
    "    img_path = os.path.join(POS_PATH, file_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    augmented_images = data_aug(img) \n",
    "    \n",
    "    for image in augmented_images:\n",
    "        cv2.imwrite(os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1())), image.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load And preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(ANC_PATH+'/*.jpg').take(300)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH+'/*.jpg').take(300)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH+'/*.jpg').take(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    \n",
    "    # Read in image from file path\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    # Load in the image \n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    \n",
    "    # Preprocessing steps - resizing the image to be 100x100x3\n",
    "    img = tf.image.resize(img, (100,100))\n",
    "    # Scale image to be between 0 and 1 \n",
    "    img = img / 255.0\n",
    "\n",
    "    # Return image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'data/anchor/f20f7cf9-a67b-11ec-a71b-84a938529240.jpg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor.as_numpy_iterator().next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=\n",
       "array([[[0.77156866, 0.7519608 , 0.74019605],\n",
       "        [0.77156866, 0.7519608 , 0.7392157 ],\n",
       "        [0.77156866, 0.7519608 , 0.7362745 ],\n",
       "        ...,\n",
       "        [0.7497549 , 0.7144608 , 0.68897057],\n",
       "        [0.7490196 , 0.7137255 , 0.69411767],\n",
       "        [0.7441176 , 0.7088235 , 0.68921566]],\n",
       "\n",
       "       [[0.7735294 , 0.75392157, 0.74215686],\n",
       "        [0.7735294 , 0.75392157, 0.7411765 ],\n",
       "        [0.7735294 , 0.75392157, 0.7382353 ],\n",
       "        ...,\n",
       "        [0.75      , 0.7147059 , 0.6887255 ],\n",
       "        [0.75      , 0.7147059 , 0.6931372 ],\n",
       "        [0.74607843, 0.7107843 , 0.68921566]],\n",
       "\n",
       "       [[0.7764706 , 0.75686276, 0.74509805],\n",
       "        [0.7764706 , 0.75686276, 0.7441176 ],\n",
       "        [0.7764706 , 0.75686276, 0.7411765 ],\n",
       "        ...,\n",
       "        [0.7529412 , 0.7176471 , 0.6960784 ],\n",
       "        [0.7519608 , 0.71666664, 0.6906863 ],\n",
       "        [0.7529412 , 0.7176471 , 0.6901961 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.6625    , 0.65857846, 0.64485294],\n",
       "        [0.6639706 , 0.6482843 , 0.6365196 ],\n",
       "        [0.660049  , 0.64142156, 0.62965685],\n",
       "        ...,\n",
       "        [0.35784313, 0.39681372, 0.5058824 ],\n",
       "        [0.36666667, 0.4019608 , 0.5176471 ],\n",
       "        [0.3752451 , 0.4105392 , 0.5242647 ]],\n",
       "\n",
       "       [[0.6490196 , 0.64509803, 0.6372549 ],\n",
       "        [0.6497549 , 0.6406863 , 0.62671566],\n",
       "        [0.6406863 , 0.63161767, 0.61764705],\n",
       "        ...,\n",
       "        [0.35588235, 0.40294117, 0.5267157 ],\n",
       "        [0.3647059 , 0.40588236, 0.5259804 ],\n",
       "        [0.3747549 , 0.41593137, 0.532598  ]],\n",
       "\n",
       "       [[0.64509803, 0.64117646, 0.6333333 ],\n",
       "        [0.62941176, 0.622549  , 0.60784316],\n",
       "        [0.63186276, 0.625     , 0.6161765 ],\n",
       "        ...,\n",
       "        [0.3480392 , 0.3990196 , 0.53039217],\n",
       "        [0.35784313, 0.40294117, 0.52843136],\n",
       "        [0.3754902 , 0.41862744, 0.5362745 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"data/anchor/fbe227ff-a67b-11ec-a54c-84a938529240.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create labelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = sample.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Train and Test Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return(preprocess(input_img), preprocess(validation_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = preprocess_twin(*example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataloader pipeline\n",
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training partition\n",
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing partition\n",
    "test_data = data.skip(round(len(data)*.7))\n",
    "test_data = test_data.take(round(len(data)*.3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedding layer\n",
    "\n",
    "def make_embedding():\n",
    "    inp = Input(shape=(100,100,3), name='input_image')\n",
    "    \n",
    "    c1 = Conv2D(64, (10,10), activation='relu')(inp)\n",
    "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
    "    \n",
    "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
    "    \n",
    "    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
    "    \n",
    "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
    "    \n",
    "    \n",
    "    return Model(inputs=[inp], outputs=[d1], name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = make_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese L1 Distance class\n",
    "class L1Dist(Layer):\n",
    "    \n",
    "    # Init method - inheritance\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "       \n",
    "    # Magic happens here - similarity calculation\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model(): \n",
    "    \n",
    "    # Anchor image input in the network\n",
    "    input_image = Input(name='input_img', shape=(100,100,3))\n",
    "    \n",
    "    # Validation image in the network \n",
    "    validation_image = Input(name='validation_img', shape=(100,100,3))\n",
    "    \n",
    "    # Combine siamese distance components\n",
    "    siamese_layer = L1Dist()\n",
    "    siamese_layer._name = 'distance'\n",
    "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
    "    \n",
    "    # Classification layer \n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "    \n",
    "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_img (InputLayer)         [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " validation_img (InputLayer)    [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)         (None, 4096)         38960448    ['input_img[0][0]',              \n",
      "                                                                  'validation_img[0][0]']         \n",
      "                                                                                                  \n",
      " distance (L1Dist)              (None, 4096)         0           ['embedding[2][0]',              \n",
      "                                                                  'embedding[3][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            4097        ['distance[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,964,545\n",
      "Trainable params: 38,964,545\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model = make_siamese_model()\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish Checkpoints\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training Step\n",
    "@tf.function\n",
    "def train_step(batch):\n",
    "    \n",
    "    # Record all of our operations \n",
    "    with tf.GradientTape() as tape:     \n",
    "        # Get anchor and positive/negative image\n",
    "        X = batch[:2]\n",
    "        # Get label\n",
    "        y = batch[2]\n",
    "        \n",
    "        # Forward pass\n",
    "        yhat = siamese_model(X, training=True)\n",
    "        # Calculate loss\n",
    "        loss = binary_cross_loss(y, yhat)\n",
    "    print(loss)\n",
    "        \n",
    "    # Calculate gradients\n",
    "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "    \n",
    "    # Calculate updated weights and apply to siamese model\n",
    "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
    "        \n",
    "    # Return loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metric calculations\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, EPOCHS):\n",
    "    # Loop through epochs\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "        \n",
    "        # Creating a metric object \n",
    "        r = Recall()\n",
    "        p = Precision()\n",
    "        \n",
    "        # Loop through each batch\n",
    "        for idx, batch in enumerate(data):\n",
    "            # Run train step here\n",
    "            loss = train_step(batch)\n",
    "            yhat = siamese_model.predict(batch[:2])\n",
    "            r.update_state(batch[2], yhat)\n",
    "            p.update_state(batch[2], yhat) \n",
    "            progbar.update(idx+1)\n",
    "        print(loss.numpy(), r.result().numpy(), p.result().numpy())\n",
    "        \n",
    "        # Save checkpoints\n",
    "        if epoch % 10 == 0: \n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1/50\n",
      "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "26/27 [===========================>..] - ETA: 0sTensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "27/27 [==============================] - 13s 185ms/step\n",
      "0.4726411 0.25870648 1.0\n",
      "\n",
      " Epoch 2/50\n",
      "27/27 [==============================] - 5s 183ms/step\n",
      "0.03083205 0.93838865 1.0\n",
      "\n",
      " Epoch 3/50\n",
      "27/27 [==============================] - 4s 160ms/step\n",
      "0.00062949123 0.9798995 0.9898477\n",
      "\n",
      " Epoch 4/50\n",
      "27/27 [==============================] - 4s 160ms/step\n",
      "0.00029029994 1.0 1.0\n",
      "\n",
      " Epoch 5/50\n",
      "27/27 [==============================] - 5s 174ms/step\n",
      "0.000104179584 0.9949495 1.0\n",
      "\n",
      " Epoch 6/50\n",
      "27/27 [==============================] - 4s 164ms/step\n",
      "0.010683576 0.9953052 1.0\n",
      "\n",
      " Epoch 7/50\n",
      "27/27 [==============================] - 4s 159ms/step\n",
      "1.4841858e-05 1.0 0.9953052\n",
      "\n",
      " Epoch 8/50\n",
      "27/27 [==============================] - 4s 159ms/step\n",
      "0.00202232 1.0 0.995283\n",
      "\n",
      " Epoch 9/50\n",
      "27/27 [==============================] - 4s 159ms/step\n",
      "0.06516875 1.0 1.0\n",
      "\n",
      " Epoch 10/50\n",
      "27/27 [==============================] - 4s 159ms/step\n",
      "0.001586797 0.98578197 0.9904762\n",
      "\n",
      " Epoch 11/50\n",
      "27/27 [==============================] - 5s 159ms/step\n",
      "0.005792315 1.0 0.99523807\n",
      "\n",
      " Epoch 12/50\n",
      "27/27 [==============================] - 4s 158ms/step\n",
      "0.0002925712 1.0 1.0\n",
      "\n",
      " Epoch 13/50\n",
      "27/27 [==============================] - 4s 158ms/step\n",
      "6.2436334e-06 1.0 1.0\n",
      "\n",
      " Epoch 14/50\n",
      "27/27 [==============================] - 4s 158ms/step\n",
      "0.0015130199 1.0 1.0\n",
      "\n",
      " Epoch 15/50\n",
      "27/27 [==============================] - 5s 178ms/step\n",
      "0.0010976442 1.0 1.0\n",
      "\n",
      " Epoch 16/50\n",
      "27/27 [==============================] - 5s 171ms/step\n",
      "7.488403e-05 1.0 1.0\n",
      "\n",
      " Epoch 17/50\n",
      "27/27 [==============================] - 4s 166ms/step\n",
      "9.509478e-05 1.0 1.0\n",
      "\n",
      " Epoch 18/50\n",
      "27/27 [==============================] - 5s 169ms/step\n",
      "0.00014956217 1.0 1.0\n",
      "\n",
      " Epoch 19/50\n",
      "27/27 [==============================] - 5s 172ms/step\n",
      "1.281501e-06 1.0 1.0\n",
      "\n",
      " Epoch 20/50\n",
      "27/27 [==============================] - 5s 173ms/step\n",
      "3.914837e-05 1.0 1.0\n",
      "\n",
      " Epoch 21/50\n",
      "27/27 [==============================] - 5s 172ms/step\n",
      "3.904119e-06 1.0 1.0\n",
      "\n",
      " Epoch 22/50\n",
      "27/27 [==============================] - 5s 173ms/step\n",
      "3.6063397e-05 1.0 1.0\n",
      "\n",
      " Epoch 23/50\n",
      "27/27 [==============================] - 5s 172ms/step\n",
      "2.673405e-05 1.0 1.0\n",
      "\n",
      " Epoch 24/50\n",
      "27/27 [==============================] - 5s 172ms/step\n",
      "4.7375142e-05 1.0 1.0\n",
      "\n",
      " Epoch 25/50\n",
      "27/27 [==============================] - 5s 171ms/step\n",
      "1.0877869e-06 1.0 1.0\n",
      "\n",
      " Epoch 26/50\n",
      "27/27 [==============================] - 5s 173ms/step\n",
      "2.7418228e-06 1.0 1.0\n",
      "\n",
      " Epoch 27/50\n",
      "27/27 [==============================] - 5s 177ms/step\n",
      "-0.0 1.0 1.0\n",
      "\n",
      " Epoch 28/50\n",
      "27/27 [==============================] - 5s 173ms/step\n",
      "0.00016965222 1.0 1.0\n",
      "\n",
      " Epoch 29/50\n",
      "27/27 [==============================] - 5s 172ms/step\n",
      "3.1637068e-05 1.0 1.0\n",
      "\n",
      " Epoch 30/50\n",
      "27/27 [==============================] - 5s 172ms/step\n",
      "1.1593262e-05 1.0 1.0\n",
      "\n",
      " Epoch 31/50\n",
      "27/27 [==============================] - 5s 172ms/step\n",
      "8.687451e-06 1.0 1.0\n",
      "\n",
      " Epoch 32/50\n",
      "27/27 [==============================] - 5s 175ms/step\n",
      "1.0103171e-05 1.0 1.0\n",
      "\n",
      " Epoch 33/50\n",
      "27/27 [==============================] - 5s 174ms/step\n",
      "1.639128e-07 1.0 1.0\n",
      "\n",
      " Epoch 34/50\n",
      "27/27 [==============================] - 5s 174ms/step\n",
      "4.7613554e-05 1.0 1.0\n",
      "\n",
      " Epoch 35/50\n",
      "27/27 [==============================] - 5s 172ms/step\n",
      "1.3709089e-06 1.0 1.0\n",
      "\n",
      " Epoch 36/50\n",
      "27/27 [==============================] - 5s 168ms/step\n",
      "0.00024058414 1.0 1.0\n",
      "\n",
      " Epoch 37/50\n",
      "27/27 [==============================] - 4s 160ms/step\n",
      "7.659277e-06 1.0 1.0\n",
      "\n",
      " Epoch 38/50\n",
      "27/27 [==============================] - 4s 161ms/step\n",
      "1.192093e-07 1.0 1.0\n",
      "\n",
      " Epoch 39/50\n",
      "27/27 [==============================] - 4s 161ms/step\n",
      "3.4272693e-07 1.0 1.0\n",
      "\n",
      " Epoch 40/50\n",
      "27/27 [==============================] - 4s 161ms/step\n",
      "1.0430815e-07 1.0 1.0\n",
      "\n",
      " Epoch 41/50\n",
      "27/27 [==============================] - 4s 160ms/step\n",
      "2.115972e-06 1.0 1.0\n",
      "\n",
      " Epoch 42/50\n",
      "27/27 [==============================] - 4s 160ms/step\n",
      "0.00016375488 1.0 1.0\n",
      "\n",
      " Epoch 43/50\n",
      "27/27 [==============================] - 4s 160ms/step\n",
      "4.8909442e-05 1.0 1.0\n",
      "\n",
      " Epoch 44/50\n",
      "27/27 [==============================] - 4s 160ms/step\n",
      "4.2470943e-05 1.0 1.0\n",
      "\n",
      " Epoch 45/50\n",
      "27/27 [==============================] - 4s 160ms/step\n",
      "7.1525676e-07 1.0 1.0\n",
      "\n",
      " Epoch 46/50\n",
      "27/27 [==============================] - 4s 160ms/step\n",
      "-0.0 1.0 1.0\n",
      "\n",
      " Epoch 47/50\n",
      "27/27 [==============================] - 4s 160ms/step\n",
      "2.3902603e-05 1.0 1.0\n",
      "\n",
      " Epoch 48/50\n",
      "27/27 [==============================] - 4s 160ms/step\n",
      "4.1711755e-05 1.0 1.0\n",
      "\n",
      " Epoch 49/50\n",
      "27/27 [==============================] - 4s 160ms/step\n",
      "2.4290073e-05 1.0 1.0\n",
      "\n",
      " Epoch 50/50\n",
      "27/27 [==============================] - 4s 160ms/step\n",
      "-0.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "train(train_data, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input, test_val, y_true = test_data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.40502285e-08],\n",
       "       [9.99999881e-01],\n",
       "       [1.08785486e-07],\n",
       "       [8.53380868e-07],\n",
       "       [1.00000000e+00],\n",
       "       [3.72569048e-07],\n",
       "       [1.00000000e+00],\n",
       "       [1.82244584e-08],\n",
       "       [9.99999881e-01],\n",
       "       [4.57443130e-05],\n",
       "       [1.00000000e+00],\n",
       "       [8.36157952e-08],\n",
       "       [4.45058674e-08],\n",
       "       [9.99827981e-01],\n",
       "       [2.44839021e-06],\n",
       "       [1.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Predictions\n",
    "predictions = siamese_model.predict([test_input, test_val])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Post processing the results\n",
    "[1 if prediction > 0.5 else 0 for prediction in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Matrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a metric object \n",
    "m = Recall()\n",
    "\n",
    "# Calculating the recall value \n",
    "m.update_state(y_true, predictions)\n",
    "\n",
    "# Return Recall Result\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a metric object \n",
    "m = Precision()\n",
    "\n",
    "# Calculating the recall value \n",
    "m.update_state(y_true, predictions)\n",
    "\n",
    "# Return Recall Result\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "r = Recall()\n",
    "p = Precision()\n",
    "\n",
    "for test_input, test_val, y_true in test_data.as_numpy_iterator():\n",
    "    yhat = siamese_model.predict([test_input, test_val])\n",
    "    r.update_state(y_true, yhat)\n",
    "    p.update_state(y_true,yhat) \n",
    "\n",
    "print(r.result().numpy(), p.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize Results\n",
    "# Set plot size \n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "# Set first subplot\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(test_input[0])\n",
    "\n",
    "# Set second subplot\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(test_val[0])\n",
    "\n",
    "# Renders cleanly\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Save weights\n",
    "siamese_model.save('siamesemodelv2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.L1Dist"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1Dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload model \n",
    "siamese_model = tf.keras.models.load_model('siamesemodelv2.h5', compile = False,\n",
    "                                   custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METRICS = [\n",
    "#       tf.keras.metrics.TruePositives(name='tp'),\n",
    "#       tf.keras.metrics.FalsePositives(name='fp'),\n",
    "#       tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "#       tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "#       tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#       tf.keras.metrics.Precision(name='precision'),\n",
    "#       tf.keras.metrics.Recall(name='recall'),\n",
    "#       tf.keras.metrics.AUC(name='auc'),\n",
    "# ]\n",
    "\n",
    "# siamese_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "#               loss = 'binary_crossentropy',\n",
    "#               metrics = METRICS\n",
    "#              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9999511e-01],\n",
       "       [8.5947534e-07],\n",
       "       [5.8255893e-07],\n",
       "       [9.9999738e-01]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with reloaded model\n",
    "siamese_model.predict([test_input, test_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_img (InputLayer)         [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " validation_img (InputLayer)    [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)         (None, 4096)         38960448    ['input_img[0][0]',              \n",
      "                                                                  'validation_img[0][0]']         \n",
      "                                                                                                  \n",
      " l1_dist_6 (L1Dist)             (None, 4096)         0           ['embedding[0][0]',              \n",
      "                                                                  'embedding[1][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            4097        ['l1_dist_6[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,964,545\n",
      "Trainable params: 38,964,545\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# View model summary\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Time Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For real time verification refer the verification.py file in the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
